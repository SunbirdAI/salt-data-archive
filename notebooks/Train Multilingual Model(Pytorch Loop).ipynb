{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13b06e57",
      "metadata": {
        "id": "13b06e57"
      },
      "source": [
        "## Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9ce02158",
      "metadata": {
        "id": "9ce02158"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "!pip install transformers\n",
        "!pip install sacrebleu\n",
        "!pip install sacremoses\n",
        "!pip install datasets\n",
        "!pip install wandb\n",
        "!pip install sentencepiece\n",
        "display.clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "36461e69",
      "metadata": {
        "id": "36461e69"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import sentencepiece\n",
        "import sacrebleu\n",
        "import sacremoses\n",
        "import tqdm\n",
        "import transformers\n",
        "import torch\n",
        "import wandb\n",
        "import torch.nn.functional as F\n",
        "from transformers import AdamW\n",
        "from transformers import get_scheduler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "c875def4-aa4a-46b1-ac1b-71e8702dcdba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c875def4-aa4a-46b1-ac1b-71e8702dcdba",
        "outputId": "41914aef-8f44-4e1e-82f2-cb5283da3a94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "xu7wVDtl6pRB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu7wVDtl6pRB",
        "outputId": "1f5c10b8-b67c-444e-b468-fcfe7a705f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Jan 24 09:44:02 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   78C    P0    32W /  70W |   2546MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ea76c66",
      "metadata": {
        "id": "3ea76c66"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "Alternatives for pre-training when translating to English: `Helsinki-NLP/opus-mt-lg-en`, `Helsinki-NLP/opus-mt-mul-en`.\n",
        "\n",
        "Note 1: when training on V100 GPUs, there is more memory and `train_batch_size` can be increased (to 64?). If this is done then `gradient_accumulation_steps` should then be decreased accordingly, so that there is the same effective batch size.\n",
        "\n",
        "Note 2: there is little difference in BLEU score when using a test set of 500 vs 1000 sentences per language. For rapid parameter tuning, we can therefore use `config['validation_samples_per_language'] = 500`, and then set it to 1000 for the best model config to report numbers in the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "64b27659",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64b27659",
        "outputId": "f8ceeafb-0579-4828-9fdc-06a3e4f1918d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating every 40 training steps.\n"
          ]
        }
      ],
      "source": [
        "# Parameters for mul-en models\n",
        "config = {\n",
        "    'source_language': 'mul',\n",
        "    'target_language': 'en',\n",
        "    'metric_for_best_model': 'BLEU_mean',\n",
        "    'metric_for_best_model_dir': 'max',\n",
        "    'train_batch_size': 20,\n",
        "    'gradient_accumulation_steps': 150,\n",
        "    'max_input_length': 128,\n",
        "    'max_target_length': 128,\n",
        "    'validation_samples_per_language': 500, #Is this not leaking?\n",
        "    'validation_train_merge': True,\n",
        "    'eval_batch_size': 16,\n",
        "    'eval_languages': [\"ach\", \"lgg\", \"lug\", \"nyn\", \"teo\"],\n",
        "    'eval_pretrained_model': True,\n",
        "    'learning_rate': 1e-4,\n",
        "    'num_train_epochs': 10,\n",
        "    'label_smoothing_factor': 0.1,\n",
        "    'flores101_training_data': True,\n",
        "    'mt560_training_data': True,\n",
        "    'back_translation_training_data': True,\n",
        "    'named_entities_training_data': True,\n",
        "    'save_checkpoint_dir': \"best_model\",\n",
        "    'beam_search_beams' :5\n",
        "}\n",
        "\n",
        "config['language_pair'] = f'{config[\"source_language\"]}-{config[\"target_language\"]}'\n",
        "config['wandb_project'] = f'salt-baseline'\n",
        "config['wandb_entity'] = f'sunbird'\n",
        "config['model_checkpoint'] = f'Helsinki-NLP/opus-mt-{config[\"language_pair\"]}'\n",
        "\n",
        "# What training data to use\n",
        "config['data_dir'] = f'v7-dataset/v7.0/supervised/{config[\"language_pair\"]}/'\n",
        "\n",
        "# Evaluate roughly every 10 minutes\n",
        "eval_steps_interval = 350 * 60 * 7 / (config['gradient_accumulation_steps']\n",
        "                                      * config['train_batch_size'])\n",
        "\n",
        "eval_steps_interval = 10 * max(1, int(eval_steps_interval / 10))\n",
        "\n",
        "print(f'Evaluating every {eval_steps_interval} training steps.')\n",
        "\n",
        "config['train_settings'] = transformers.Seq2SeqTrainingArguments(\n",
        "    f'output-{config[\"language_pair\"]}',\n",
        "    evaluation_strategy = 'steps',\n",
        "    eval_steps = eval_steps_interval,\n",
        "    save_steps = eval_steps_interval,\n",
        "    gradient_accumulation_steps = config['gradient_accumulation_steps'],\n",
        "    learning_rate = config['learning_rate'],\n",
        "    per_device_train_batch_size = config['train_batch_size'],\n",
        "    per_device_eval_batch_size = config['eval_batch_size'],\n",
        "    weight_decay = 0.01,\n",
        "    save_total_limit = 3,\n",
        "    num_train_epochs = config['num_train_epochs'],\n",
        "    predict_with_generate = True,\n",
        "    fp16 = torch.cuda.is_available(),\n",
        "    logging_dir = f'output-{config[\"language_pair\"]}',\n",
        "    report_to = 'none',\n",
        "    run_name = f'{config[\"source_language\"]}-{config[\"target_language\"]}',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model = config['metric_for_best_model'],\n",
        "    label_smoothing_factor = config['label_smoothing_factor']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dade6a8-9f93-4d64-8fec-e4462bf425e9",
      "metadata": {
        "id": "0dade6a8-9f93-4d64-8fec-e4462bf425e9"
      },
      "source": [
        "MT560 is much bigger than the other training sets, so oversample the rest (by 5x) to balance it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "64b7ae1b-0675-4c78-bf9a-22d40ae9f930",
      "metadata": {
        "id": "64b7ae1b-0675-4c78-bf9a-22d40ae9f930"
      },
      "outputs": [],
      "source": [
        "if config[\"validation_train_merge\"]: #WARNING: this will introduce an indirect leak because the validation set will be the test set as well\n",
        "\n",
        "    config['training_subset_ids'] = [\n",
        "        'train', 'train_ai4d',\n",
        "        'val_ach', 'val_lgg', 'val_lug', 'val_nyn', 'val_teo', #FIXME\n",
        "    ]\n",
        "else:\n",
        "    config['validation_subset_ids'] = [\n",
        "        'train', 'train_ai4d'\n",
        "    ]\n",
        "\n",
        "    config['validation_subset_ids'] = [\n",
        "        'val_ach', 'val_lgg', 'val_lug', 'val_nyn', 'val_teo', #FIXME\n",
        "    ]\n",
        "\n",
        "    config['training_subset_ids']\n",
        "\n",
        "if config['flores101_training_data']:\n",
        "    config['training_subset_ids'] .append('train_flores_lug')\n",
        "\n",
        "if config['back_translation_training_data']:\n",
        "    config['training_subset_ids'].append('back_translated')\n",
        "\n",
        "# Over-sample the non-religious training text\n",
        "config['training_subset_ids'] = config['training_subset_ids'] * 5\n",
        "\n",
        "if config['mt560_training_data']:\n",
        "    config['training_subset_ids'].extend([\n",
        "        'train_mt560_lug', 'train_mt560_ach', 'train_mt560_nyn',\n",
        "    ])\n",
        "\n",
        "if config['named_entities_training_data']:\n",
        "    config['training_subset_ids'].append('named_entities')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f607807-40be-4cda-8fa7-67abb72f0234",
      "metadata": {
        "id": "9f607807-40be-4cda-8fa7-67abb72f0234"
      },
      "source": [
        "# Set up datasets\n",
        "\n",
        "Download the raw text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "29dcda22-59ab-49b3-b2fd-5a8b200dead2",
      "metadata": {
        "id": "29dcda22-59ab-49b3-b2fd-5a8b200dead2"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('v7-dataset'):\n",
        "    !wget https://sunbird-translate.s3.us-east-2.amazonaws.com/v7-dataset.zip\n",
        "    !unzip v7-dataset.zip\n",
        "    display.clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "E7zz-rjk0fU1",
      "metadata": {
        "id": "E7zz-rjk0fU1"
      },
      "outputs": [],
      "source": [
        "if not os.path.isfile('salt-training-extra-mul-en.zip'):\n",
        "    !gdown 1bqnR42oAiAR4su24oq0ABGHuWmfzWnrO\n",
        "    !unzip salt-training-extra-mul-en.zip -d /content/v7-dataset/v7.0/supervised/mul-en/\n",
        "    display.clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2332961c-fb4b-4249-bac1-2c8e4384faa2",
      "metadata": {
        "id": "2332961c-fb4b-4249-bac1-2c8e4384faa2"
      },
      "source": [
        "Create a training set by interleaving separate training subsets.\n",
        "\n",
        "Notes:\n",
        "* This includes MT560 which has many examples (484,925), but which is biased towards religious text so we sample from it sparsely.\n",
        "* We just use a 2-way train/test split for this experiment, so include the validation sentences in with the training set.\n",
        "* LGG, ACH and TEO are oversampled a little by duplicating the validation sets, as a simple way to correct for there being more LUG and NYN training data.\n",
        "What would duplicating the val data do, as it has nothing to do with gradients. This would work for overfitting and whatnot but not training? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "1db95e17-5b8a-473f-b38f-2303ca7d9f66",
      "metadata": {
        "id": "1db95e17-5b8a-473f-b38f-2303ca7d9f66"
      },
      "outputs": [],
      "source": [
        "def _file_to_list(path):\n",
        "    with open(path) as file:\n",
        "        lines = file.readlines()\n",
        "        lines = [line.rstrip() for line in lines]\n",
        "        return lines\n",
        "    \n",
        "def dataset_from_src_tgt_files(data_dir, dataset_id, validation_cutoff = 0, mode = \"train\"):\n",
        "    \"\"\"\n",
        "        validation_cutoff: use first n lines as validation\n",
        "    \"\"\"\n",
        "\n",
        "    path = os.path.join(data_dir, dataset_id)\n",
        "    source, target = [_file_to_list(path + '.src'),\n",
        "                      _file_to_list(path + '.tgt')]\n",
        "    if mode == \"cutoff_maximum\":\n",
        "        source = source[:validation_cutoff]\n",
        "        target = target[:validation_cutoff]\n",
        "    elif mode == \"cutoff_minimum\":\n",
        "        source = source[validation_cutoff:]\n",
        "        target = target[validation_cutoff:]\n",
        "\n",
        "    pairs = {'translation': [{config['source_language']: s,\n",
        "                              config['target_language']: t}\n",
        "                             for s, t in zip(source, target)]}\n",
        "    return datasets.Dataset.from_dict(pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "50887e34-b0c7-40d2-8e00-2cfa525a3e06",
      "metadata": {
        "id": "50887e34-b0c7-40d2-8e00-2cfa525a3e06"
      },
      "outputs": [],
      "source": [
        "if config[\"validation_train_merge\"]: #WARNING: this will introduce an indirect leak because the validation set will be the test set as well\n",
        "    training_subsets = [dataset_from_src_tgt_files(config['data_dir'], id, \n",
        "                            validation_cutoff = config['validation_samples_per_language'], mode = \"cutoff_minimum\")\n",
        "                        for id in config['training_subset_ids']]\n",
        "else:\n",
        "    training_subsets = [dataset_from_src_tgt_files(config['data_dir'], id,\n",
        "                                                   validation_cutoff = 0, mode=\"cutoff_minimum\") #Takes all the training data as a whole, doesn't split into validation\n",
        "                    for id in config['training_subset_ids']]\n",
        "\n",
        "\n",
        "training_subsets = [s.shuffle() for s in training_subsets]\n",
        "\n",
        "\n",
        "sample_probabilities = np.array([len(s) for s in training_subsets])\n",
        "sample_probabilities = sample_probabilities / np.sum(sample_probabilities)\n",
        "\n",
        "train_data_raw = datasets.interleave_datasets(\n",
        "    training_subsets, sample_probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "hOaMYdUc7wvg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hOaMYdUc7wvg",
        "outputId": "ccff08fd-a88b-4690-eebe-663fefe9cd49"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'v7-dataset/v7.0/supervised/mul-en/'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config['data_dir']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd838152-63c9-45ef-830d-564d6d34b72f",
      "metadata": {
        "id": "cd838152-63c9-45ef-830d-564d6d34b72f"
      },
      "source": [
        "Make the separate validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "0e273c90-378b-46fd-b07b-52a3caa3725b",
      "metadata": {
        "id": "0e273c90-378b-46fd-b07b-52a3caa3725b"
      },
      "outputs": [],
      "source": [
        "if config[\"validation_train_merge\"]: #WARNING: this will introduce an indirect leak because the validation set will be the test set as well\n",
        "    validation_subsets = [dataset_from_src_tgt_files(\n",
        "        config['data_dir'], f'test_{lang}', validation_cutoff = config['validation_samples_per_language'],\n",
        "        mode = \"cutoff_maximum\"\n",
        "        )\n",
        "        for lang in config['eval_languages']]\n",
        "else:\n",
        "    validation_subsets = [dataset_from_src_tgt_files(config['data_dir'], id,\n",
        "                                                     validation_cutoff = 0, mode=\"cutoff_minimum\")  #Takes all the validation data as a whole, doesn't split into validation\n",
        "                    for id in config['validation_subset_ids']]\n",
        "    \n",
        "\n",
        "validation_data_raw = datasets.concatenate_datasets(validation_subsets)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "841b26f9",
      "metadata": {
        "id": "841b26f9"
      },
      "source": [
        "## Helper functions\n",
        "\n",
        "Note that whatever pre-processing we do here (punctuation normalisation and ensuring sentence case), we should also do at test-time when running the model on real queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "dda8c8a2",
      "metadata": {
        "id": "dda8c8a2"
      },
      "outputs": [],
      "source": [
        "def sentence_format(input):\n",
        "    '''Ensure capital letter at the start and full stop at the end.'''\n",
        "    input = input[0].capitalize() + input[1:]\n",
        "    if input[-1] not in ['.', '!', '?']:\n",
        "        input = input + '.'\n",
        "    return input\n",
        "\n",
        "def preprocess(examples):\n",
        "    normalizer = sacremoses.MosesPunctNormalizer()\n",
        "    \n",
        "    inputs = [ex[config['source_language']] for ex in examples['translation']]\n",
        "    targets = [ex[config['target_language']] for ex in examples['translation']]\n",
        "\n",
        "    inputs = [sentence_format(normalizer.normalize(text))\n",
        "              for text in inputs]\n",
        "    targets = [sentence_format(normalizer.normalize(text))\n",
        "               for text in targets]\n",
        "    \n",
        "    model_inputs = tokenizer(\n",
        "        inputs, max_length=config['max_input_length'], truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            targets, max_length=config['max_target_length'], truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "def postprocess(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds, eval_languages, samples_per_language):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess(decoded_preds, decoded_labels)\n",
        "    \n",
        "    result = {}\n",
        "    for i, lang in enumerate(eval_languages):\n",
        "        result_subset = metric.compute(\n",
        "            predictions=decoded_preds[i*samples_per_language:(i+1)*samples_per_language],\n",
        "            references=decoded_labels[i*samples_per_language:(i+1)*samples_per_language])\n",
        "        result[f\"BLEU_{lang}\"] = result_subset[\"score\"]\n",
        "        \n",
        "    result[\"BLEU_mean\"] = np.mean([result[f\"BLEU_{lang}\"] for lang in eval_languages])\n",
        "    \n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81a392ae",
      "metadata": {
        "id": "81a392ae"
      },
      "source": [
        "# Training\n",
        "\n",
        "Instantiate the model and tokenizer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6f7e240-2824-4862-80e0-5dbb4c0de094",
      "metadata": {
        "id": "a6f7e240-2824-4862-80e0-5dbb4c0de094"
      },
      "source": [
        "For multiple language outputs, we need to make sure the language codes have some mapping in the encoder. We can re-use the token indices of some other language codes in the pre-trained model that we don't need.\n",
        "\n",
        "In `Helsinki-NLP/opus-mt-en-mul`, only Luganda (`lug`) is already supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "7a6c9a37-c7a7-4954-a6d7-fe3d44dfb1d6",
      "metadata": {
        "id": "7a6c9a37-c7a7-4954-a6d7-fe3d44dfb1d6"
      },
      "outputs": [],
      "source": [
        "if config['target_language'] == 'mul':\n",
        "    replacements = {'nyn': 'kin',\n",
        "                    'lgg': 'lin',\n",
        "                    'ach': 'tso',\n",
        "                    'teo': 'som',\n",
        "                    'luo': 'sna'}\n",
        "    for r in replacements:\n",
        "        if (f'>>{r}<<' not in tokenizer.encoder and\n",
        "            f'>>{replacements[r]}<<' in tokenizer.encoder):\n",
        "            tokenizer.encoder[f\">>{r}<<\"] = tokenizer.encoder[f\">>{replacements[r]}<<\"]\n",
        "            del tokenizer.encoder[f\">>{replacements[r]}<<\"]\n",
        "\n",
        "    # Check that all the evaluation language codes are mapped to something.\n",
        "    for r in config['eval_languages']:\n",
        "        if f'>>{r}<<' not in tokenizer.encoder:\n",
        "            raise ValueError(f'Language code {r} not found in the encoder.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9331d9b",
      "metadata": {
        "id": "e9331d9b"
      },
      "source": [
        "Pre-process the raw text datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "ffd05d31-b8e2-4049-bbb4-8abbeafacbf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "7f10f32ae7414a4f972a470e2e574e47",
            "12c82645e6384642be398373b67c668a",
            "2ef9824ee3064043baa6c39e573d778f",
            "0d914a0fa45840c29140693b524dbeee",
            "aee2bde115a2488a8d555f570db2bfca",
            "bf6008dfc864499795e357666fbf4198",
            "f962e3964d714dd285ea49fa3ebbd1e7",
            "b5dc12abc1c74f549fb6352106921223",
            "1d713d2f242e497abbcdeef73446c3ac",
            "8ff03d959c6248ca8ae4fc1932c514c5",
            "20729af3264f46649da9743da8d921f0",
            "d34cc42c4d57495eb72c741525b8cc18",
            "16ed73df8b764419891f627b41f141c5",
            "ec09819747784bd1a733bcc686167d99",
            "18a12eb74c5044499b5e85899d941d6a",
            "ca3f63ae91c94537b89e70eaafaa3d21",
            "011762d2203a48d48cacc6ce04c21f52",
            "6c9c90c0a3484bfd88b9cc703f878bc8",
            "58023d87847a41b4a4c3b0357a1f8dc7",
            "41ba6af5358e4bec96707e64ac873c9c",
            "01c4f0c1a9d34e10819dbc0bc6b4f049",
            "db409d2b897e4833afbf673ba342da99"
          ]
        },
        "id": "ffd05d31-b8e2-4049-bbb4-8abbeafacbf8",
        "outputId": "d200d01d-8a0a-45d2-f08b-2f02cc13b161"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f10f32ae7414a4f972a470e2e574e47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1322 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3578: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d34cc42c4d57495eb72c741525b8cc18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_data  = train_data_raw.map(\n",
        "    preprocess, remove_columns=[\"translation\"], batched=True)\n",
        "\n",
        "validation_data  = validation_data_raw.map(\n",
        "    preprocess, remove_columns=[\"translation\"], batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a0ec59a",
      "metadata": {
        "id": "7a0ec59a"
      },
      "source": [
        "Launch the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "14fUvEaw-oxf",
      "metadata": {
        "id": "14fUvEaw-oxf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_data, shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    validation_data, batch_size=5, collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "59977cde",
      "metadata": {
        "id": "59977cde"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = transformers.AutoModelForSeq2SeqLM.from_pretrained(config['model_checkpoint'])\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(config['model_checkpoint'])\n",
        "data_collator = transformers.DataCollatorForSeq2Seq(tokenizer, model = model) \n",
        "metric = datasets.load_metric('sacrebleu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "5uYNaEmFDC8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uYNaEmFDC8c",
        "outputId": "756e6d9a-4e50-49b5-b696-722f8cf2fe81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "495624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "-WmYWiTADdKU",
      "metadata": {
        "id": "-WmYWiTADdKU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "display.clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "Xz2F5cX6lcXJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "Xz2F5cX6lcXJ",
        "outputId": "f68535fc-1598-4150-912e-a9f7771b2bff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:oer5jrfc) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BLEU_ach</td><td>▁</td></tr><tr><td>BLEU_lgg</td><td>▁</td></tr><tr><td>BLEU_lug</td><td>▁</td></tr><tr><td>BLEU_mean</td><td>▁</td></tr><tr><td>BLEU_nyn</td><td>▁</td></tr><tr><td>BLEU_teo</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BLEU_ach</td><td>0.7135</td></tr><tr><td>BLEU_lgg</td><td>0.8453</td></tr><tr><td>BLEU_lug</td><td>13.7493</td></tr><tr><td>BLEU_mean</td><td>3.8016</td></tr><tr><td>BLEU_nyn</td><td>3.1336</td></tr><tr><td>BLEU_teo</td><td>0.5662</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">red-goat-3</strong> at: <a href=\"https://wandb.ai/sunbird/salt-baseline/runs/oer5jrfc\" target=\"_blank\">https://wandb.ai/sunbird/salt-baseline/runs/oer5jrfc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230124_114847-oer5jrfc/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:oer5jrfc). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230124_115318-ml3axxkj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sunbird/salt-baseline/runs/ml3axxkj\" target=\"_blank\">bright-ox-4</a></strong> to <a href=\"https://wandb.ai/sunbird/salt-baseline\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href=\"https://wandb.ai/sunbird/salt-baseline\" target=\"_blank\">https://wandb.ai/sunbird/salt-baseline</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href=\"https://wandb.ai/sunbird/salt-baseline/runs/ml3axxkj\" target=\"_blank\">https://wandb.ai/sunbird/salt-baseline/runs/ml3axxkj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sunbird/salt-baseline/runs/ml3axxkj?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f37e77a84f0>"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(project=config[\"wandb_project\"], entity=config[\"wandb_entity\"], config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yJql0DPnDnHd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "9efa1beaae9b4203b495c589432fc18c",
            "688b01d0b3f24f2d81b0359331a3fb7c",
            "3a111b54add3430db524d6f404e62a4c",
            "a761530bfb0d422ea9835c9e16479810",
            "0489ba12457f4a82a6c76215b9656a06",
            "3ce011eb9a3b411c994bd52a85ee4f02",
            "0b1d610cc3744bde88ced971c6675d8d",
            "6ceb9d1ee11c4a61bc22bccdc5f5d12f",
            "207e952803eb442ba6abd7f0492a69bc",
            "59b739abd23f4c1594a34758610ae421",
            "f1578e760074442883e1108e129ee234"
          ]
        },
        "id": "yJql0DPnDnHd",
        "outputId": "46a92e19-065f-4114-e783-3e524fa45dbf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9efa1beaae9b4203b495c589432fc18c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/495624 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'BLEU_ach': 0.8202, 'BLEU_lgg': 0.9588, 'BLEU_lug': 14.0596, 'BLEU_nyn': 4.1003, 'BLEU_teo': 0.6618, 'BLEU_mean': 4.1201}\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "assert config[\"max_input_length\"] == config[\"max_target_length\"]\n",
        "\n",
        "model.train()\n",
        "best_validation_metric = 0 \n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        if batch_idx%10000 == 0:\n",
        "            model.eval()\n",
        "            all_outs = []\n",
        "            all_labels = []\n",
        "            for batch in eval_dataloader:\n",
        "                batch = {k: v.to(device) for k, v in batch.items()}\n",
        "                with torch.no_grad():\n",
        "                    outputs = model.generate(batch[\"input_ids\"], num_beams=config[\"beam_search_beams\"], max_length = config[\"max_input_length\"])\n",
        "                all_outs.append(outputs.cpu())\n",
        "                all_labels.append(batch[\"labels\"].cpu())\n",
        "\n",
        "            for idx in range(len(all_outs)):\n",
        "                all_outs[idx] = F.pad(all_outs[idx],(0,config[\"max_input_length\"]-all_outs[idx].shape[1]))\n",
        "                all_labels[idx] = F.pad(all_labels[idx],(0,config[\"max_target_length\"]-all_labels[idx].shape[1]))\n",
        "            all_outs = torch.cat(all_outs)\n",
        "            all_labels = torch.cat(all_labels)\n",
        "\n",
        "            val_metrics = compute_metrics((all_outs, all_labels), config['eval_languages'], config[\"validation_samples_per_language\"])\n",
        "            print(val_metrics)\n",
        "            wandb.log(val_metrics)\n",
        "            validation_metric = val_metrics[config[\"metric_for_best_model\"]] #FIXME loss not included\n",
        "            \n",
        "            if config[\"metric_for_best_model\"] == \"max\": #If we are maximizing not minimizing add a negative to the metric \n",
        "                validation_metric = -validation_metric\n",
        "            if best_validation_metric >= validation_metric:\n",
        "                best_validation_metric = validation_metric\n",
        "                model.save_pretrained( config[\"save_checkpoint_dir\"] )\n",
        "            del all_outs, all_labels\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zuU_jMr_noy0",
      "metadata": {
        "id": "zuU_jMr_noy0"
      },
      "source": [
        "Garbage collection cell to free up VRAM, run only if you want to delete the model data from memory and start again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "cRcmz6dzOjxE",
      "metadata": {
        "id": "cRcmz6dzOjxE"
      },
      "outputs": [],
      "source": [
        "\n",
        "import gc\n",
        "\n",
        "model.cpu()\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "011762d2203a48d48cacc6ce04c21f52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c4f0c1a9d34e10819dbc0bc6b4f049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0489ba12457f4a82a6c76215b9656a06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b1d610cc3744bde88ced971c6675d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d914a0fa45840c29140693b524dbeee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ff03d959c6248ca8ae4fc1932c514c5",
            "placeholder": "​",
            "style": "IPY_MODEL_20729af3264f46649da9743da8d921f0",
            "value": " 1322/1322 [07:30&lt;00:00,  3.59ba/s]"
          }
        },
        "12c82645e6384642be398373b67c668a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf6008dfc864499795e357666fbf4198",
            "placeholder": "​",
            "style": "IPY_MODEL_f962e3964d714dd285ea49fa3ebbd1e7",
            "value": "100%"
          }
        },
        "16ed73df8b764419891f627b41f141c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_011762d2203a48d48cacc6ce04c21f52",
            "placeholder": "​",
            "style": "IPY_MODEL_6c9c90c0a3484bfd88b9cc703f878bc8",
            "value": "100%"
          }
        },
        "18a12eb74c5044499b5e85899d941d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01c4f0c1a9d34e10819dbc0bc6b4f049",
            "placeholder": "​",
            "style": "IPY_MODEL_db409d2b897e4833afbf673ba342da99",
            "value": " 3/3 [00:00&lt;00:00,  4.63ba/s]"
          }
        },
        "1d713d2f242e497abbcdeef73446c3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20729af3264f46649da9743da8d921f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "207e952803eb442ba6abd7f0492a69bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ef9824ee3064043baa6c39e573d778f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5dc12abc1c74f549fb6352106921223",
            "max": 1322,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d713d2f242e497abbcdeef73446c3ac",
            "value": 1322
          }
        },
        "3a111b54add3430db524d6f404e62a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ceb9d1ee11c4a61bc22bccdc5f5d12f",
            "max": 495624,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_207e952803eb442ba6abd7f0492a69bc",
            "value": 8187
          }
        },
        "3ce011eb9a3b411c994bd52a85ee4f02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ba6af5358e4bec96707e64ac873c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58023d87847a41b4a4c3b0357a1f8dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59b739abd23f4c1594a34758610ae421": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688b01d0b3f24f2d81b0359331a3fb7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce011eb9a3b411c994bd52a85ee4f02",
            "placeholder": "​",
            "style": "IPY_MODEL_0b1d610cc3744bde88ced971c6675d8d",
            "value": "  2%"
          }
        },
        "6c9c90c0a3484bfd88b9cc703f878bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ceb9d1ee11c4a61bc22bccdc5f5d12f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f10f32ae7414a4f972a470e2e574e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12c82645e6384642be398373b67c668a",
              "IPY_MODEL_2ef9824ee3064043baa6c39e573d778f",
              "IPY_MODEL_0d914a0fa45840c29140693b524dbeee"
            ],
            "layout": "IPY_MODEL_aee2bde115a2488a8d555f570db2bfca"
          }
        },
        "8ff03d959c6248ca8ae4fc1932c514c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9efa1beaae9b4203b495c589432fc18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_688b01d0b3f24f2d81b0359331a3fb7c",
              "IPY_MODEL_3a111b54add3430db524d6f404e62a4c",
              "IPY_MODEL_a761530bfb0d422ea9835c9e16479810"
            ],
            "layout": "IPY_MODEL_0489ba12457f4a82a6c76215b9656a06"
          }
        },
        "a761530bfb0d422ea9835c9e16479810": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b739abd23f4c1594a34758610ae421",
            "placeholder": "​",
            "style": "IPY_MODEL_f1578e760074442883e1108e129ee234",
            "value": " 8187/495624 [14:35&lt;11:14:55, 12.04it/s]"
          }
        },
        "aee2bde115a2488a8d555f570db2bfca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5dc12abc1c74f549fb6352106921223": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf6008dfc864499795e357666fbf4198": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3f63ae91c94537b89e70eaafaa3d21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d34cc42c4d57495eb72c741525b8cc18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16ed73df8b764419891f627b41f141c5",
              "IPY_MODEL_ec09819747784bd1a733bcc686167d99",
              "IPY_MODEL_18a12eb74c5044499b5e85899d941d6a"
            ],
            "layout": "IPY_MODEL_ca3f63ae91c94537b89e70eaafaa3d21"
          }
        },
        "db409d2b897e4833afbf673ba342da99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec09819747784bd1a733bcc686167d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58023d87847a41b4a4c3b0357a1f8dc7",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41ba6af5358e4bec96707e64ac873c9c",
            "value": 3
          }
        },
        "f1578e760074442883e1108e129ee234": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f962e3964d714dd285ea49fa3ebbd1e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
